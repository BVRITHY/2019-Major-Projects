{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\guris\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\guris\\anaconda3\\lib\\site-packages (from torch) (1.6.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\guris\\anaconda3\\lib\\site-packages (from torch) (2.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\guris\\anaconda3\\lib\\site-packages (from torch) (2.11.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\guris\\anaconda3\\lib\\site-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\guris\\anaconda3\\lib\\site-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\guris\\anaconda3\\lib\\site-packages (from sympy->torch) (1.1.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\guris\\anaconda3\\lib\\site-packages (from networkx->torch) (4.4.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\guris\\anaconda3\\lib\\site-packages (from jinja2->torch) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_label_dict = {\"CG\" : 0, \"OR\" : 1}\n",
    "def encode_label(x):\n",
    "    return encoded_label_dict.get(x,-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\guris\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\guris\\anaconda3\\lib\\site-packages (0.15.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\guris\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\guris\\anaconda3\\lib\\site-packages (from torch) (1.6.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\guris\\anaconda3\\lib\\site-packages (from torch) (2.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\guris\\anaconda3\\lib\\site-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\guris\\anaconda3\\lib\\site-packages (from torch) (2.11.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\guris\\anaconda3\\lib\\site-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\guris\\anaconda3\\lib\\site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\guris\\anaconda3\\lib\\site-packages (from torchvision) (8.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\guris\\anaconda3\\lib\\site-packages (from torchvision) (2.24.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\guris\\anaconda3\\lib\\site-packages (from sympy->torch) (1.1.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\guris\\anaconda3\\lib\\site-packages (from networkx->torch) (4.4.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\guris\\anaconda3\\lib\\site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\guris\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\guris\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\guris\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\guris\\anaconda3\\lib\\site-packages (from requests->torchvision) (2020.6.20)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"fake reviews dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target\"] = df[\"label\"].apply(lambda x: encode_label(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"roberta-base\"\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 8\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Triage(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        title = str(self.data.text[index])\n",
    "        title = \" \".join(title.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            title,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.data.target[index], dtype=torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (40432, 5)\n",
      "TRAIN Dataset: (32345, 5)\n",
      "VALID Dataset: (8087, 5)\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataset and dataloader\n",
    "train_dataset, valid_dataset = train_test_split(df, test_size=0.2, shuffle=True, random_state=2021)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "valid_dataset = valid_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"VALID Dataset: {}\".format(valid_dataset.shape))\n",
    "\n",
    "training_set = Triage(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = Triage(valid_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "valid_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **valid_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(model_name)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcuate_accu(big_idx, targets):\n",
    "    n_correct = (big_idx==targets).sum().item()\n",
    "    return n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    tr_loss = 0\n",
    "    n_correct = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    model.train()\n",
    "    for _,data in enumerate(training_loader, 0):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(ids, attention_mask=mask, labels=targets)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        tr_loss += loss\n",
    "        big_val, big_idx = torch.max(logits, dim=1)\n",
    "        n_correct += calcuate_accu(big_idx, targets)\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples+=targets.size(0)\n",
    "        \n",
    "        if _!=0 and _%100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            accu_step = (n_correct*100)/nb_tr_examples \n",
    "            print(f\"Training Loss per 100 steps: {loss_step}\")\n",
    "            print(f\"Training Accuracy per 100 steps: {accu_step}\")\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    model.eval()\n",
    "    n_correct = 0\n",
    "    n_wrong = 0\n",
    "    total = 0\n",
    "    tr_loss = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(testing_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.long)\n",
    "            outputs = model(ids, attention_mask=mask, labels=targets)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            tr_loss += loss\n",
    "            big_val, big_idx = torch.max(logits, dim=1)\n",
    "            n_correct += calcuate_accu(big_idx, targets)\n",
    "\n",
    "            nb_tr_steps += 1\n",
    "            nb_tr_examples+=targets.size(0)\n",
    "            \n",
    "            if _!=0 and _%100==0:\n",
    "                loss_step = tr_loss/nb_tr_steps\n",
    "                accu_step = (n_correct*100)/nb_tr_examples\n",
    "                print(f\"Validation Loss per 100 steps: {loss_step}\")\n",
    "                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    print(f\"Validation Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n",
    "    \n",
    "    return epoch_accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guris\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 100 steps: 0.587766706943512\n",
      "Training Accuracy per 100 steps: 66.70792079207921\n",
      "Training Loss per 100 steps: 0.4383002519607544\n",
      "Training Accuracy per 100 steps: 77.48756218905473\n",
      "Training Loss per 100 steps: 0.36642393469810486\n",
      "Training Accuracy per 100 steps: 81.97674418604652\n",
      "Training Loss per 100 steps: 0.328593373298645\n",
      "Training Accuracy per 100 steps: 84.35162094763092\n",
      "Training Loss per 100 steps: 0.2900194525718689\n",
      "Training Accuracy per 100 steps: 86.37724550898204\n",
      "Training Loss per 100 steps: 0.265490859746933\n",
      "Training Accuracy per 100 steps: 87.72878535773711\n",
      "Training Loss per 100 steps: 0.25204533338546753\n",
      "Training Accuracy per 100 steps: 88.56990014265335\n",
      "Training Loss per 100 steps: 0.2335241287946701\n",
      "Training Accuracy per 100 steps: 89.55992509363296\n",
      "Training Loss per 100 steps: 0.22076600790023804\n",
      "Training Accuracy per 100 steps: 90.14983351831299\n",
      "Training Loss per 100 steps: 0.21037831902503967\n",
      "Training Accuracy per 100 steps: 90.70929070929071\n",
      "Training Loss per 100 steps: 0.2036047875881195\n",
      "Training Accuracy per 100 steps: 91.06494096276113\n",
      "Training Loss per 100 steps: 0.19320815801620483\n",
      "Training Accuracy per 100 steps: 91.56952539550375\n",
      "Training Loss per 100 steps: 0.1866268664598465\n",
      "Training Accuracy per 100 steps: 91.91006917755573\n",
      "Training Loss per 100 steps: 0.18171851336956024\n",
      "Training Accuracy per 100 steps: 92.18415417558886\n",
      "Training Loss per 100 steps: 0.17682990431785583\n",
      "Training Accuracy per 100 steps: 92.40506329113924\n",
      "Training Loss per 100 steps: 0.17139171063899994\n",
      "Training Accuracy per 100 steps: 92.63741411617738\n",
      "Training Loss per 100 steps: 0.16711649298667908\n",
      "Training Accuracy per 100 steps: 92.85714285714286\n",
      "Training Loss per 100 steps: 0.1645888090133667\n",
      "Training Accuracy per 100 steps: 93.01082731815659\n",
      "Training Loss per 100 steps: 0.16008175909519196\n",
      "Training Accuracy per 100 steps: 93.22067332982641\n",
      "Training Loss per 100 steps: 0.1572868525981903\n",
      "Training Accuracy per 100 steps: 93.33458270864568\n",
      "Training Loss per 100 steps: 0.15406063199043274\n",
      "Training Accuracy per 100 steps: 93.46144693003332\n",
      "Training Loss per 100 steps: 0.15165206789970398\n",
      "Training Accuracy per 100 steps: 93.59382099045888\n",
      "Training Loss per 100 steps: 0.1479133665561676\n",
      "Training Accuracy per 100 steps: 93.75814863102998\n",
      "Training Loss per 100 steps: 0.1456945836544037\n",
      "Training Accuracy per 100 steps: 93.84631403581841\n",
      "Training Loss per 100 steps: 0.1436794251203537\n",
      "Training Accuracy per 100 steps: 93.95241903238704\n",
      "Training Loss per 100 steps: 0.14196936786174774\n",
      "Training Accuracy per 100 steps: 94.02153018069973\n",
      "Training Loss per 100 steps: 0.13940803706645966\n",
      "Training Accuracy per 100 steps: 94.16419844502036\n",
      "Training Loss per 100 steps: 0.13743536174297333\n",
      "Training Accuracy per 100 steps: 94.25205283827205\n",
      "Training Loss per 100 steps: 0.1340775191783905\n",
      "Training Accuracy per 100 steps: 94.38555670458463\n",
      "Training Loss per 100 steps: 0.13167303800582886\n",
      "Training Accuracy per 100 steps: 94.51016327890703\n",
      "Training Loss per 100 steps: 0.13024237751960754\n",
      "Training Accuracy per 100 steps: 94.57029990325701\n",
      "Training Loss per 100 steps: 0.1284545361995697\n",
      "Training Accuracy per 100 steps: 94.65401437050922\n",
      "Training Loss per 100 steps: 0.12707839906215668\n",
      "Training Accuracy per 100 steps: 94.70614965162072\n",
      "Training Loss per 100 steps: 0.12552854418754578\n",
      "Training Accuracy per 100 steps: 94.80667450749779\n",
      "Training Loss per 100 steps: 0.12412016093730927\n",
      "Training Accuracy per 100 steps: 94.86932305055699\n",
      "Training Loss per 100 steps: 0.1223394125699997\n",
      "Training Accuracy per 100 steps: 94.96320466537072\n",
      "Training Loss per 100 steps: 0.12141213566064835\n",
      "Training Accuracy per 100 steps: 95.0047284517698\n",
      "Training Loss per 100 steps: 0.1205255314707756\n",
      "Training Accuracy per 100 steps: 95.05064456721915\n",
      "Training Loss per 100 steps: 0.11885704845190048\n",
      "Training Accuracy per 100 steps: 95.14227121250961\n",
      "Training Loss per 100 steps: 0.11741716414690018\n",
      "Training Accuracy per 100 steps: 95.18870282429393\n",
      "The Total Accuracy for Epoch 0: 95.2110063379193\n",
      "Training Loss Epoch: 0.117082379758358\n",
      "Training Accuracy Epoch: 95.2110063379193\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss per 100 steps: 0.0801875963807106\n",
      "Validation Accuracy per 100 steps: 96.16336633663366\n",
      "Validation Loss per 100 steps: 0.08032133430242538\n",
      "Validation Accuracy per 100 steps: 96.08208955223881\n",
      "Validation Loss per 100 steps: 0.08778281509876251\n",
      "Validation Accuracy per 100 steps: 96.05481727574751\n",
      "Validation Loss per 100 steps: 0.0871008038520813\n",
      "Validation Accuracy per 100 steps: 96.2281795511222\n",
      "Validation Loss per 100 steps: 0.08614528924226761\n",
      "Validation Accuracy per 100 steps: 96.33233532934132\n",
      "Validation Loss per 100 steps: 0.08726959675550461\n",
      "Validation Accuracy per 100 steps: 96.3810316139767\n",
      "Validation Loss per 100 steps: 0.08765775710344315\n",
      "Validation Accuracy per 100 steps: 96.30884450784593\n",
      "Validation Loss per 100 steps: 0.08520614355802536\n",
      "Validation Accuracy per 100 steps: 96.39513108614233\n",
      "Validation Loss per 100 steps: 0.08418260514736176\n",
      "Validation Accuracy per 100 steps: 96.44839067702553\n",
      "Validation Loss per 100 steps: 0.08675521612167358\n",
      "Validation Accuracy per 100 steps: 96.35364635364635\n",
      "Validation Loss Epoch: 0.08653189241886139\n",
      "Validation Accuracy Epoch: 96.36453567453938\n",
      "Accuracy on validation data = 96.36%\n"
     ]
    }
   ],
   "source": [
    "acc = valid(model, testing_loader)\n",
    "print(\"Accuracy on validation data = %0.2f%%\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files saved\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "output_model_file = 'ft-roberta-amazonreviews.pt'\n",
    "model_to_save = model\n",
    "torch.save(model_to_save, output_model_file)\n",
    "print('All files saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"roberta-base\"\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('ft-roberta-amazonreviews.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Probability: 0.9984105825424194\n",
      "Fake Probability: 0.0015893701929599047\n"
     ]
    }
   ],
   "source": [
    "device=\"cpu\"\n",
    "query = \"\"\"I work in the wedding industry and have to work long days, on my feet, outside in the heat, and have to look professional. I've spent a ridiculous amount of money on high end dress shoes like Merrels and just have not been able to find a pair that are comfortable to wear all day. Both for my feet and my back. Enter the Sanuk yoga sling!!! These shoes are amazingly comfortable. Though, I will admit it took a few wears to get used to the feel of the yoga matte bottom. At first, it felt a little \"sticky\" to me, and the fabric part that goes through the toe area was a little thick and took some getting used to. I wore them for a few days before taking them out on a job and I can't get over how comfortable they are. Ii have been wearing these shoes now for 3 months, every work day and I am THRILLED. No more back pain, no more sore feet. I also wear these sometimes during my off time,mans every time I wear them, I get compliments on how cute and comfortable they look. The great thing about these shoes is the yoga matte bottom. It helps your feet grip to the shoe a bit, so your foot can just walk normally, without having to grip the shoe. You may not realize it, but with a lot of Sandals, your foot is having to work to keep the shoe on, changing the way you walk and stand and ultimately causing foot and back pain. Not with these! Also, the soft linen sits comfortably on your skin and breathes nicely in the heat. The only downside is the funky tan lines, which is why I am sure to alternate shoes on my days off, especially if I plan to be outside for most of the day. If it were not for that, I think these might be the only shoes I'd wear all summer. If you are looking for a reasonable priced, comfortable shoe that you can wear and walk in all day.\"\"\"\n",
    "tokens = tokenizer.encode(query,return_tensors=\"pt\")\n",
    "all_tokens = len(tokens)\n",
    "mask = torch.ones_like(tokens)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(tokens.to(device), attention_mask=mask.to(device))[0]\n",
    "    probs = logits.softmax(dim=-1)\n",
    "\n",
    "fake, real = probs.detach().cpu().flatten().numpy().tolist()\n",
    "\n",
    "print(f\"Real Probability: {real}\\nFake Probability: {fake}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Probability: 0.9984105825424194\n",
      "Fake Probability: 0.0015893701929599047\n"
     ]
    }
   ],
   "source": [
    "device=\"cpu\"\n",
    "query = \"\"\"I work in the wedding industry and have to work long days, on my feet, outside in the heat, and have to look professional. I've spent a ridiculous amount of money on high end dress shoes like Merrels and just have not been able to find a pair that are comfortable to wear all day. Both for my feet and my back. Enter the Sanuk yoga sling!!! These shoes are amazingly comfortable. Though, I will admit it took a few wears to get used to the feel of the yoga matte bottom. At first, it felt a little \"sticky\" to me, and the fabric part that goes through the toe area was a little thick and took some getting used to. I wore them for a few days before taking them out on a job and I can't get over how comfortable they are. Ii have been wearing these shoes now for 3 months, every work day and I am THRILLED. No more back pain, no more sore feet. I also wear these sometimes during my off time,mans every time I wear them, I get compliments on how cute and comfortable they look. The great thing about these shoes is the yoga matte bottom. It helps your feet grip to the shoe a bit, so your foot can just walk normally, without having to grip the shoe. You may not realize it, but with a lot of Sandals, your foot is having to work to keep the shoe on, changing the way you walk and stand and ultimately causing foot and back pain. Not with these! Also, the soft linen sits comfortably on your skin and breathes nicely in the heat. The only downside is the funky tan lines, which is why I am sure to alternate shoes on my days off, especially if I plan to be outside for most of the day. If it were not for that, I think these might be the only shoes I'd wear all summer. If you are looking for a reasonable priced, comfortable shoe that you can wear and walk in all day.\"\"\"\n",
    "tokens = tokenizer.encode(query,return_tensors=\"pt\")\n",
    "all_tokens = len(tokens)\n",
    "mask = torch.ones_like(tokens)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(tokens.to(device), attention_mask=mask.to(device))[0]\n",
    "    probs = logits.softmax(dim=-1)\n",
    "\n",
    "fake, real = probs.detach().cpu().flatten().numpy().tolist()\n",
    "\n",
    "print(f\"Real Probability: {real}\\nFake Probability: {fake}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(query, model, tokenizer, device=\"cpu\"):\n",
    "    tokens = tokenizer.encode(query)\n",
    "    all_tokens = len(tokens)\n",
    "    tokens = tokens[:tokenizer.model_max_length - 2]\n",
    "    used_tokens = len(tokens)\n",
    "    tokens = torch.tensor([tokenizer.bos_token_id] + tokens + [tokenizer.eos_token_id]).unsqueeze(0)\n",
    "    mask = torch.ones_like(tokens)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(tokens.to(device), attention_mask=mask.to(device))[0]\n",
    "        probs = logits.softmax(dim=-1)\n",
    "\n",
    "    fake, real = probs.detach().cpu().flatten().numpy().tolist()\n",
    "    return real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8681015968322754"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"Fabric is very thin. Keeping it for the colour and print.\"\"\"\n",
    "predict(query,model,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, preds_probas = [],[]\n",
    "for i, row in valid_dataset.iterrows():\n",
    "    query = row[\"text\"]\n",
    "    pred = predict(query,model,tokenizer)\n",
    "    preds_probas.append(pred)\n",
    "    if pred >= 0.5:\n",
    "        preds.append(1)\n",
    "    else:\n",
    "        preds.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3931,   79],\n",
       "       [ 239, 3838]], dtype=int64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = valid_dataset.target.values\n",
    "y_pred = preds\n",
    "confusion_matrix(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "acc = accuracy_score(y_true,y_pred)\n",
    "precision = precision_score(y_true,y_pred)\n",
    "recall = recall_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.0677630765426; Precision:97.98315037018126; Recall:94.13784645572724\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {acc*100}; Precision:{precision*100}; Recall:{recall*100}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CG       0.94      0.98      0.96      4010\n",
      "          OR       0.98      0.94      0.96      4077\n",
      "\n",
      "    accuracy                           0.96      8087\n",
      "   macro avg       0.96      0.96      0.96      8087\n",
      "weighted avg       0.96      0.96      0.96      8087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=[\"CG\",\"OR\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df_rows = []\n",
    "for i, row in valid_dataset.iterrows():\n",
    "    query = row[\"text\"]\n",
    "    pred_prob = preds_probas[i]\n",
    "    pred_label = preds[i]\n",
    "    preds_df_rows.append([pred_prob,pred_label])\n",
    "preds_df = pd.DataFrame(preds_df_rows, columns=[\"Finetune_Roberta_Model_Probability\",\"Finetune_Roberta_Model_Prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df.to_csv(\"ft_roberta_predictions.csv\", index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
